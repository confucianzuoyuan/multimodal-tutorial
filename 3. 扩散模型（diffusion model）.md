
扩散模型的兴起可以看作是近年来 AI 生成艺术作品领域取得突破的主要因素。

在本文中，我将通过示意图来解释它的工作原理。

## 概述

![[Pasted image 20250903163226.png]]

扩散模型的训练可以分为两部分：

1. 正向扩散过程→给图像添加噪声。
2. 反向扩散过程→从图像中去除噪声。

## 正向扩散过程

![[Pasted image 20250903163405.png]]

![[3.1.excalidraw|1000]]

前向扩散过程逐步将高斯噪声添加到输入图像 $x_0$ 中，总共会有 $T$ 步。该过程将产生一系列带噪声的图像样本 $x_1, \dots, x_T$ 。

当 $T → ∞$ 时，最终结果将变成完全噪声图像，就像从 ==各向同性== 的高斯分布中采样出来的噪声一样。

但我们不需要设计一种算法来迭代地向图像中添加噪声，而是可以使用闭式公式（解析解）在特定的时间步长 $t$ 直接对噪声图像进行采样。

## 闭式公式（解析解）

可以使用重新参数化技巧推导出闭形式的采样公式。

首先，如果 $z\sim\mathcal{N}(\mu,\sigma^2)$ 的话，那么有下面的结论

$$
z = \mu + \sigma\epsilon \quad\text{其中}\epsilon\sim\mathcal{N}(0, 1)
$$

利用这个技巧，我们可以将采样图像 $x_t$ 表示如下：

$$
x_t = \sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta_t}\epsilon_{t-1}
$$

==然后我们可以递归地展开它来得到闭合形式的公式：==

![[Pasted image 20250903171507.png]]

```ad-tip
所有 $\epsilon$ 都是 $i.i.d.$（独立同分布）标准正态随机变量。

使用不同的符号和下标来区分它们非常重要，因为它们是独立的，并且在采样后它们的值可能会有所不同。
```

但是我们如何从第 4 行跳到第 5 行呢？

![[Pasted image 20250903171649.png]]

有些人觉得这个步骤比较难理解。我们推导一下：

![[3.2.excalidraw|1000]]

我们用 $X$ 和 $Y$ 来表示这两个项。它们可以被视为来自两个不同正态分布的样本。即

$$
X\sim\mathcal{N}(0,\alpha_t(1-\alpha_{t-1})I)
$$

和

$$
Y\sim\mathcal{N}(0,(1-\alpha_{t})I)
$$

回想一下，两个正态分布（独立）随机变量的和也是正态分布的。即，如果 $Z=X+Y$ ，那么有下面的公式

$$
Z\sim\mathcal{N}(0, \sigma^2_X+\sigma^2_Y)
$$

因此，我们可以将它们合并在一起，并以重新参数化的形式表示合并后的正态分布。这就是我们将这两个项合并的方法。

重复这些步骤将为我们提供以下仅取决于输入图像 $x_0$ 的公式：

$$
x_t = \sqrt{\overline{\alpha}_t}+\sqrt{1-\overline{\alpha}_t}\epsilon
$$

现在我们可以使用此公式在任何时间步骤直接对 $x_t$ 进行采样，这使得前向过程更快。

## 反向扩散过程

![[3.3.excalidraw|1000]]

与前向过程不同，我们不能使用 $q(x_{t-1}|x_t)$ 来逆转噪声，因为它是难以处理的（不可计算的）。

因此，我们需要训练一个神经网络 $p_\theta(x_{t-1}|x_t)$ 来近似 $q(x_{t-1}|x_t)$ 。近似值 $p_\theta(x_{t-1}|x_t)$ 服从正态分布，其均值和方差如下：

$$
\begin{cases}
\mu_\theta(x_t, t) &:= \tilde{\mu}_t(x_t, x_0) \\
\Sigma_\theta(x_t, t) &:= \beta_t I
\end{cases}
$$

## 损失函数

我们可以将损失定义为负对数似然：

![[3.4.excalidraw|1000]]


这里的问题与 VAE（变分自编码器）中的问题非常相似。我们可以优化变分下界，而不是优化难以解决的损失函数本身。

![[3.5.excalidraw|1000]]

通过优化可计算的下界函数，我们可以间接优化难以解决的损失函数。

![[3.6.excalidraw|1000]]

==变分下界的推导与扩展==

通过扩展变分下界，我们发现它可以用以下三个项表示：

**1. 常数项** ：$L_T$

由于 $q$ 没有可学习的参数，而 $p$ 只是高斯噪声概率，因此该项在训练期间将是一个常数，因此可以忽略不计。

**2. 逐步去噪项** ：$L_{t-1}$

该项将目标去噪步骤 $q$ 与近似去噪步骤 $p_θ$ 进行比较。

```ad-tip
请注意，通过对 $x_0$ 进行条件分析，$q(x_{t-1}|x_t,x_0)$ 变得容易处理。
```

![[Pasted image 20250903183013.png]]

经过一系列推导，平均值 $\tilde{\mu}_t$ 的 $q(x_{t-1}|x_t,x_0)$ 如上所示。

平均值的推导过程见最后。

为了近似目标去噪步长 $q$ ，我们只需使用神经网络近似其均值即可。因此，我们将近似均值 $\mu_\theta$ 设置为与目标均值 $\tilde{\mu}_t$ 相同的形式（使用可学习的神经网络 $\epsilon_\theta$ ）：

![[Pasted image 20250903183630.png]]

可以使用均方误差（MSE）来比较目标均值和近似均值：

![[Pasted image 20250903183650.png]]

实验表明，忽略加权项并简单地计算目标噪声和预测噪声的 MSE 可以获得更好的结果。

**3. 重建项** ：$L_0$

这是最后一步去噪的重建损失，由于以下原因，可以在训练期间忽略它：

- 它可以使用 $L_{t-1}$ 中的相同神经网络来近似。
- 忽略它会使样本质量更好，并且使其更易于实现。

## 简化损失

因此最终简化的训练目标如下：

![[Pasted image 20250903183903.png]]

## U-Net模型

### 数据集

在每个 Epoch：

1. 将为每个训练样本（图像）选择一个随机时间步长 $t$ 。
2. 对每幅图像应用高斯噪声（对应于 $t$ ）。
3. 将时间步长转换为嵌入（向量）。

![[Pasted image 20250903184137.png]]

### 训练

![[Pasted image 20250903184217.png]]

官方的训练算法如上，下图是一个训练步骤的示意图：

![[Pasted image 20250903184307.png]]

### 反向扩散

![[Pasted image 20250903184406.png]]

我们可以使用上述算法从噪声中生成图像。下图是它的说明：

![[Pasted image 20250903184424.png]]

请注意，在最后一步，我们只是输出学习到的平均值 $\mu_\theta(x_1,1)$ ，而不向其中添加噪声。

## 平均值 $\tilde{\mu}_t$ 的详细推导

以下是损失函数部分中逐步去噪项中 $q(x_{t-1}|x_t,x_0)$ 的平均值 $\tilde{\mu}_t$ 的详细推导。

![[Pasted image 20250903184722.png]]

